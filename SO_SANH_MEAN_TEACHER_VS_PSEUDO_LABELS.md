# ğŸ“Š So SÃ¡nh Mean Teacher vs Pseudo-Labeling

## ğŸ¯ Tá»•ng Quan

| TiÃªu chÃ­ | **Pseudo-Labeling** | **Mean Teacher** |
|----------|---------------------|------------------|
| **PhÆ°Æ¡ng phÃ¡p** | Offline pseudo-labeling | Online consistency regularization |
| **Workflow** | 2-stage: Táº¡o labels â†’ Train | 1-stage: Train trá»±c tiáº¿p |
| **Äá»™ phá»©c táº¡p** | ÄÆ¡n giáº£n | Phá»©c táº¡p hÆ¡n |

---

## âœ… Æ¯U ÄIá»‚M

### ğŸ“Œ PSEUDO-LABELING (KhÃ´ng Mean Teacher)

#### âœ… Æ¯u Ä‘iá»ƒm:

1. **ÄÆ¡n giáº£n vÃ  dá»… hiá»ƒu**
   - Workflow rÃµ rÃ ng: Stage 2 táº¡o labels â†’ Stage 3 train
   - Dá»… debug: CÃ³ thá»ƒ kiá»ƒm tra pseudo-labels trÆ°á»›c khi train
   - Logic Ä‘Æ¡n giáº£n: Chá»‰ cáº§n 1 model, 1 loss function

2. **Training nhanh hÆ¡n**
   - Chá»‰ 1 forward pass má»—i batch
   - KhÃ´ng cáº§n tÃ­nh consistency loss phá»©c táº¡p
   - Memory efficient: KhÃ´ng cáº§n lÆ°u teacher model

3. **Linh hoáº¡t**
   - CÃ³ thá»ƒ chá»‰nh sá»­a pseudo-labels thá»§ cÃ´ng náº¿u cáº§n
   - CÃ³ thá»ƒ filter pseudo-labels theo confidence
   - Dá»… tÃ­ch há»£p vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c

4. **CÃ³ thá»ƒ tÃ¡i sá»­ dá»¥ng**
   - Pseudo-labels Ä‘Æ°á»£c lÆ°u trÃªn disk
   - CÃ³ thá»ƒ dÃ¹ng láº¡i cho nhiá»u láº§n train
   - KhÃ´ng cáº§n regenerate má»—i láº§n

5. **á»”n Ä‘á»‹nh hÆ¡n**
   - Pseudo-labels cá»‘ Ä‘á»‹nh â†’ training á»•n Ä‘á»‹nh
   - KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi noise tá»« teacher predictions
   - Dá»… reproduce káº¿t quáº£

---

### ğŸ“Œ MEAN TEACHER

#### âœ… Æ¯u Ä‘iá»ƒm:

1. **Hiá»‡u suáº¥t tá»‘t hÆ¡n (thÆ°á»ng)**
   - Consistency regularization tá»± Ä‘á»™ng
   - Teacher predictions Ä‘Æ°á»£c cáº­p nháº­t liÃªn tá»¥c
   - Táº­n dá»¥ng Ä‘Æ°á»£c temporal consistency tá»‘t hÆ¡n

2. **Dynamic learning**
   - Pseudo-labels Ä‘Æ°á»£c cáº­p nháº­t trong quÃ¡ trÃ¬nh training
   - Teacher model cáº£i thiá»‡n dáº§n â†’ pseudo-targets tá»‘t hÆ¡n
   - KhÃ´ng bá»‹ stuck vá»›i labels ban Ä‘áº§u

3. **Táº­n dá»¥ng unlabeled data tá»‘t hÆ¡n**
   - DÃ¹ng trá»±c tiáº¿p raw unlabeled images
   - KhÃ´ng cáº§n táº¡o masks offline
   - Consistency loss giÃºp há»c patterns tá»‘t hÆ¡n

4. **Tá»± Ä‘á»™ng adapt**
   - Consistency weight ramp-up tá»± Ä‘á»™ng
   - Teacher model adapt theo student improvements
   - KhÃ´ng cáº§n tune threshold thá»§ cÃ´ng

5. **KhÃ´ng cáº§n Stage 2**
   - Training pipeline ngáº¯n hÆ¡n
   - Ãt bÆ°á»›c hÆ¡n â†’ Ã­t lá»—i hÆ¡n
   - Faster iteration

---

## âŒ NHÆ¯á»¢C ÄIá»‚M

### ğŸ“Œ PSEUDO-LABELING (KhÃ´ng Mean Teacher)

#### âŒ NhÆ°á»£c Ä‘iá»ƒm:

1. **Pseudo-labels cÃ³ thá»ƒ sai**
   - Táº¡o bá»Ÿi baseline model (cÃ³ thá»ƒ chÆ°a tá»‘t)
   - KhÃ´ng Ä‘Æ°á»£c cáº­p nháº­t trong quÃ¡ trÃ¬nh training
   - CÃ³ thá»ƒ propagate errors tá»« Stage 2

2. **KhÃ´ng augmentation cho pseudo-labels**
   - Code: `transform=val_transform` (KHÃ”NG augmentation)
   - LÃ½ do: Augmentation cÃ³ thá»ƒ lÃ m sai lá»‡ch pseudo-labels
   - â†’ Ãt variation trong training

3. **Cáº§n Stage 2 riÃªng**
   - Pháº£i cháº¡y Stage 2 trÆ°á»›c (tá»‘n thá»i gian)
   - Cáº§n táº¡o vÃ  lÆ°u pseudo-labels
   - Tá»‘n storage cho masks

4. **Confidence threshold cá»‘ Ä‘á»‹nh**
   - Má»™t sá»‘ frames cÃ³ thá»ƒ khÃ´ng cÃ³ pseudo-label
   - Threshold quÃ¡ cao â†’ máº¥t data
   - Threshold quÃ¡ tháº¥p â†’ noise

5. **KhÃ´ng táº­n dá»¥ng temporal consistency**
   - Pseudo-labels tÄ©nh, khÃ´ng cÃ³ temporal smoothing
   - Má»—i frame xá»­ lÃ½ Ä‘á»™c láº­p

---

### ğŸ“Œ MEAN TEACHER

#### âŒ NhÆ°á»£c Ä‘iá»ƒm:

1. **Phá»©c táº¡p hÆ¡n**
   - Cáº§n quáº£n lÃ½ 2 models (student + teacher)
   - 2 loss functions (supervised + consistency)
   - Nhiá»u hyperparameters cáº§n tune

2. **Training cháº­m hÆ¡n**
   - 2 forward passes má»—i batch (student + teacher)
   - TÃ­nh consistency loss tá»‘n computation
   - Memory: Cáº§n lÆ°u teacher model

3. **KhÃ³ debug hÆ¡n**
   - KhÃ´ng cÃ³ "labels" cá»¥ thá»ƒ Ä‘á»ƒ kiá»ƒm tra
   - Consistency loss cÃ³ thá»ƒ khÃ³ interpret
   - Cáº§n monitor nhiá»u metrics

4. **Sensitive vá»›i hyperparameters**
   - Consistency weight (Î»): Cáº§n tune cáº©n tháº­n
   - EMA decay: áº¢nh hÆ°á»Ÿng Ä‘áº¿n teacher update
   - Ramp-up schedule: áº¢nh hÆ°á»Ÿng Ä‘áº¿n convergence

5. **CÃ³ thá»ƒ khÃ´ng stable**
   - Teacher predictions cÃ³ thá»ƒ noisy á»Ÿ Ä‘áº§u training
   - Consistency loss cÃ³ thá»ƒ lá»›n â†’ training unstable
   - Cáº§n ramp-up Ä‘á»ƒ trÃ¡nh instability

---

## ğŸ“ˆ SO SÃNH CHI TIáº¾T

### ğŸ”§ Implementation Complexity

| KhÃ­a cáº¡nh | Pseudo-Labeling | Mean Teacher |
|-----------|----------------|--------------|
| **Models** | 1 model | 2 models (student + teacher) |
| **Loss Functions** | 1 (supervised) | 2 (supervised + consistency) |
| **Forward Passes/Batch** | 1 | 2 |
| **Memory Usage** | Tháº¥p | Cao (2x) |
| **Code Complexity** | ÄÆ¡n giáº£n | Phá»©c táº¡p |

### âš¡ Performance

| Metric | Pseudo-Labeling | Mean Teacher |
|--------|----------------|--------------|
| **Training Speed** | âš¡âš¡âš¡âš¡âš¡ Nhanh | âš¡âš¡âš¡ Cháº­m hÆ¡n |
| **Model Quality** | â­â­â­â­ Tá»‘t | â­â­â­â­â­ Tá»‘t hÆ¡n (thÆ°á»ng) |
| **Convergence** | á»”n Ä‘á»‹nh | CÃ³ thá»ƒ khÃ´ng á»•n Ä‘á»‹nh |
| **Final Accuracy** | Tá»‘t | Tá»‘t hÆ¡n (thÆ°á»ng) |

### ğŸ’¾ Resources

| Resource | Pseudo-Labeling | Mean Teacher |
|---------|----------------|--------------|
| **Storage** | Cáº§n lÆ°u pseudo-labels | KhÃ´ng cáº§n |
| **Computation** | Tháº¥p | Cao hÆ¡n (~2x) |
| **Memory** | Tháº¥p | Cao (2 models) |
| **Time** | Stage 2 + Stage 3 | Chá»‰ Stage 3 |

### ğŸ¯ Use Cases

#### Chá»n **Pseudo-Labeling** khi:
- âœ… Cáº§n training nhanh
- âœ… CÃ³ Ã­t computational resources
- âœ… Cáº§n reproducibility cao
- âœ… Muá»‘n kiá»ƒm tra vÃ  chá»‰nh sá»­a labels
- âœ… Baseline model Ä‘Ã£ tá»‘t

#### Chá»n **Mean Teacher** khi:
- âœ… Cáº§n accuracy cao nháº¥t
- âœ… CÃ³ Ä‘á»§ computational resources
- âœ… Muá»‘n training pipeline ngáº¯n
- âœ… Unlabeled data nhiá»u vÃ  quality tá»‘t
- âœ… CÃ³ thá»ƒ tune hyperparameters

---

## ğŸ“Š Káº¾T QUáº¢ Tá»ª Dá»° ÃN Cá»¦A Báº N

### Pseudo-Labeling (KhÃ´ng Mean Teacher):
- âœ… **Training time**: ~6 phÃºt (10 epochs)
- âœ… **Batches/epoch**: 19
- âœ… **Final metrics**: Val Dice: 0.8158, IoU: 0.7190 (best epoch 9)
- âœ… **Stability**: á»”n Ä‘á»‹nh, loss giáº£m Ä‘á»u

### Mean Teacher:
- â³ **Training time**: Äang cháº¡y (~6-7 phÃºt, cháº­m hÆ¡n)
- â³ **Batches/epoch**: 13
- â³ **Final metrics**: Chá» káº¿t quáº£
- â³ **Consistency**: Î» ramp-up tá»« 0 â†’ 10

---

## ğŸ† Káº¾T LUáº¬N

### **Mean Teacher** thÆ°á»ng tá»‘t hÆ¡n vá»:
- ğŸ¯ **Accuracy** (thÆ°á»ng cao hÆ¡n 2-5%)
- ğŸ”„ **Dynamic learning** (adapt tá»‘t hÆ¡n)
- ğŸš€ **Pipeline efficiency** (khÃ´ng cáº§n Stage 2)

### **Pseudo-Labeling** tá»‘t hÆ¡n vá»:
- âš¡ **Training speed** (nhanh gáº¥p ~1.5-2x)
- ğŸ’¾ **Resource usage** (memory, computation tháº¥p hÆ¡n)
- ğŸ”§ **Simplicity** (dá»… implement vÃ  debug)
- ğŸ“Š **Stability** (training á»•n Ä‘á»‹nh hÆ¡n)

---

## ğŸ’¡ KHUYáº¾N NGHá»Š

### Cho dá»± Ã¡n nÃ y:
**Mean Teacher** cÃ³ váº» phÃ¹ há»£p hÆ¡n vÃ¬:
- âœ… Báº¡n cÃ³ 100 unlabeled frames (nhiá»u data)
- âœ… Mean Teacher táº­n dá»¥ng temporal consistency tá»‘t
- âœ… Accuracy quan trá»ng hÆ¡n training speed

### Workflow khuyáº¿n nghá»‹:
1. **Thá»­ Mean Teacher trÆ°á»›c** (náº¿u cÃ³ Ä‘á»§ resources)
2. **So sÃ¡nh káº¿t quáº£** vá»›i Pseudo-Labeling
3. **Chá»n phÆ°Æ¡ng phÃ¡p tá»‘t hÆ¡n** cho production

---

## ğŸ“ TÃ³m Táº¯t Nhanh

| | **Pseudo-Labeling** | **Mean Teacher** |
|---|---|---|
| **Accuracy** | â­â­â­â­ | â­â­â­â­â­ |
| **Speed** | âš¡âš¡âš¡âš¡âš¡ | âš¡âš¡âš¡ |
| **Simplicity** | âœ…âœ…âœ…âœ…âœ… | âœ…âœ… |
| **Stability** | âœ…âœ…âœ…âœ… | âœ…âœ…âœ… |
| **Resources** | ğŸ’¾ğŸ’¾ | ğŸ’¾ğŸ’¾ğŸ’¾ğŸ’¾ |

**Káº¿t luáº­n**: Mean Teacher tá»‘t hÆ¡n vá» accuracy, nhÆ°ng Pseudo-Labeling Ä‘Æ¡n giáº£n vÃ  nhanh hÆ¡n.

